<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <title>Doctor - WebRTC Call</title>
  <style>
    * { 
      margin: 0; 
      padding: 0; 
      box-sizing: border-box;
      -webkit-tap-highlight-color: transparent;
    }
    
    body { 
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif;
      background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
      min-height: 100vh;
      padding: 10px;
      overflow-x: hidden;
    }
    
    h2 { 
      color: white; 
      text-align: center; 
      margin: 10px 0 20px 0;
      font-size: 24px;
      text-shadow: 0 2px 4px rgba(0,0,0,0.3);
    }
    
    #status { 
      padding: 12px 15px;
      margin: 0 0 15px 0;
      background: rgba(255,255,255,0.95);
      border-radius: 12px;
      font-size: 14px;
      text-align: center;
      font-weight: 500;
      box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    
    .video-container {
      display: flex;
      flex-direction: column;
      gap: 10px;
      margin-bottom: 15px;
    }
    
    video { 
      width: 100%;
      max-width: 100%;
      height: auto;
      aspect-ratio: 4/3;
      border-radius: 12px;
      border: 3px solid rgba(255,255,255,0.3);
      background: #000;
      object-fit: cover;
      box-shadow: 0 8px 16px rgba(0,0,0,0.3);
    }
    
    #local { 
      transform: scaleX(-1);
      -webkit-transform: scaleX(-1);
    }
    
    button { 
      width: 100%;
      padding: 16px 20px;
      font-size: 18px;
      font-weight: 600;
      border: none;
      border-radius: 12px;
      cursor: pointer;
      transition: all 0.3s ease;
      box-shadow: 0 4px 6px rgba(0,0,0,0.1);
      -webkit-appearance: none;
      touch-action: manipulation;
    }
    
    #acceptBtn {
      display: none;
      background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
      color: white;
    }
    
    #acceptBtn:active {
      transform: scale(0.98);
      box-shadow: 0 2px 4px rgba(0,0,0,0.2);
    }
    
    #acceptBtn:disabled {
      background: #ccc;
      cursor: not-allowed;
      opacity: 0.6;
    }
    
    /* iOS Safari specific fixes */
    @supports (-webkit-touch-callout: none) {
      video {
        -webkit-mask-image: -webkit-radial-gradient(white, black);
      }
    }
    
    /* Landscape mode adjustments */
    @media (orientation: landscape) and (max-height: 500px) {
      .video-container {
        flex-direction: row;
      }
      video {
        width: 48%;
      }
      h2 {
        font-size: 18px;
        margin: 5px 0;
      }
    }
    
    /* Larger screens */
    @media (min-width: 768px) {
      body {
        padding: 20px;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
      }
      .video-container {
        max-width: 600px;
        width: 100%;
      }
      button {
        max-width: 400px;
      }
      h2 {
        font-size: 32px;
      }
    }
  </style>
</head>
<body>
  <h2>üë®‚Äç‚öïÔ∏è Doctor</h2>
  <div id="status">Status: Connecting...</div>
  <div class="video-container">
    <video id="local" autoplay muted playsinline webkit-playsinline></video>
    <video id="remote" autoplay playsinline webkit-playsinline controls></video>
  </div>
  <button id="acceptBtn" onclick="acceptCall()" disabled>‚úÖ Accept Call</button>

  <script>
    let socket = null;
    let pc = null;
    let localStream = null;
    let pendingOffer = null;
    let pendingIceCandidates = [];
    let remoteStream = null;
    let tracksReceived = 0;
    const statusDiv = document.getElementById('status');
    const acceptBtn = document.getElementById('acceptBtn');

    // Initialize WebSocket connection
    function connectWebSocket() {
      statusDiv.textContent = 'Status: Connecting to server...';
      
      socket = new WebSocket("wss://web-m4g9.onrender.com");
      
      socket.onopen = () => {
        console.log("‚úì WebSocket connected");
        statusDiv.textContent = 'Status: Waiting for calls...';
        socket.send(JSON.stringify({ type: "LOGIN", userId: "doctor" }));
      };
      
      socket.onerror = (error) => {
        console.error("‚úó WebSocket error:", error);
        statusDiv.textContent = 'Status: Connection error';
      };
      
      socket.onclose = () => {
        console.log("‚úó WebSocket closed");
        statusDiv.textContent = 'Status: Disconnected - Reconnecting...';
        acceptBtn.style.display = 'none';
        
        // Try to reconnect after 2 seconds
        setTimeout(connectWebSocket, 2000);
      };
      
      socket.onmessage = async (msg) => {
        try {
          const data = JSON.parse(msg.data);
          console.log("‚Üê Received:", data.type);
          
          if (data.type === "OFFER") {
            console.log("  Incoming call!");
            pendingOffer = data.offer;
            acceptBtn.style.display = 'inline-block';
            acceptBtn.disabled = !localStream;
            acceptBtn.textContent = 'Accept Call';
            statusDiv.textContent = 'Status: Incoming call from Phone!';
            
            // Play a beep or show notification
            const audio = new Audio('data:audio/wav;base64,UklGRnoGAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQoGAACBhYqFbF1fdJivrJBhNjVgodDbq2EcBj+a2/LDciUFLIHO8tiJNwgZaLvt559NEAxQp+PwtmMcBjiR1/LMeSwFJHfH8N2QQAoUXrTp66hVFApGn+DyvmwhBSuBzvLZiTYIG2m98OWhUBELTKXh8bllHgU2jdXvypQxByZ6x+/glEILE16y5+ypWBUIQ5zd8L9pJAUuhM/y2Ik3CBlsu/Ho0qVcFQ1NoOHwuWUdBTWN1e/KlDEHJnrH7+CUQgsUXrLn7KlZFQhDnN3wv2kkBS6Ez/HYijYIG2y77eeNRBMMUKvn7qRcFQ1NouDvuGEcBjaN1+/KlDIIJnrH7+GUQgsUX7Hn7KlYFQlDnN3wv2kkBS6Ez/HYijYIG2y67eeMRBMMUKvn7qRcFQ1NouDvuGEcBjaN1+/KlDIIJnrH7+GUQgsUX7Hn7KlYFQlDnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQgsUX7Hn7KlYFQlCnN3wv2kkBS+Ez/HYijcHG2y77eeNRRMMT6zn7qRcFQ1NouDvuGEcBjaN1+/KlDIHJnrH7+GUQg==');
            audio.play().catch(e => console.log("Cannot play audio:", e));
          }
          
          if (data.type === "ICE") {
            console.log("  Received ICE candidate");
            if (pendingOffer) {
              // Store ICE candidates until call is accepted
              pendingIceCandidates.push(data.candidate);
            } else if (pc && data.candidate) {
              // Call already accepted, add ICE candidate immediately
              await pc.addIceCandidate(new RTCIceCandidate(data.candidate));
            }
          }
        } catch (error) {
          console.error("Error processing message:", error);
        }
      };
    }

    // Initialize peer connection
    function initPeerConnection() {
      const config = {
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' },
          { urls: 'stun:stun1.l.google.com:19302' }
        ]
      };
      
      console.log("Creating peer connection with config:", config);
      pc = new RTCPeerConnection(config);
      
      pc.ontrack = (e) => {
        console.log("‚úì Received track:", e.track.kind, "from stream:", e.streams[0].id);
        console.log("Track state:", e.track.readyState, "enabled:", e.track.enabled);
        
        tracksReceived++;
        remoteStream = e.streams[0];
        
        // Wait for both audio and video tracks before setting stream
        if (tracksReceived >= 2) {
          const remoteVideo = document.getElementById('remote');
          remoteVideo.srcObject = remoteStream;
          statusDiv.textContent = 'Status: In call';
          
          console.log("‚úì Remote video stream set with both tracks");
          console.log("Stream tracks:", remoteStream.getTracks().map(t => `${t.kind} (${t.readyState})`));
          console.log("Video readyState:", remoteVideo.readyState);
          console.log("üì° Current ICE state:", pc.iceConnectionState);
          console.log("üì° Current connection state:", pc.connectionState);
          
          // Try to play immediately
          const tryPlay = () => {
            console.log("Attempting to play video...");
            remoteVideo.play().then(() => {
              console.log("‚úì‚úì‚úì Remote video is now playing!");
            }).catch(err => {
              console.error("Remote video play error:", err);
            });
          };
          
          // If metadata already loaded, play immediately
          if (remoteVideo.readyState >= 1) {
            console.log("Metadata already loaded (readyState:", remoteVideo.readyState + ")");
            tryPlay();
          } else {
            // Wait for metadata to load
            console.log("Waiting for metadata to load...");
            remoteVideo.onloadedmetadata = () => {
              console.log("‚úì Video metadata loaded event fired");
              tryPlay();
            };
          }
        } else {
          console.log(`Waiting for more tracks... (${tracksReceived}/2)`);
        }
      };
      
      pc.onicecandidate = (e) => {
        if (e.candidate) {
          console.log("‚Üí ICE candidate generated:", e.candidate.type, e.candidate.protocol);
          if (socket && socket.readyState === WebSocket.OPEN) {
            console.log("  Sending to phone...");
            socket.send(JSON.stringify({
              type: "ICE",
              to: "phone",
              candidate: e.candidate
            }));
          } else {
            console.error("  ‚úó Cannot send - socket not ready!");
          }
        } else {
          console.log("‚úì ICE gathering complete (null candidate)");
        }
      };
      
      pc.oniceconnectionstatechange = () => {
        console.log("üì° ICE state:", pc.iceConnectionState);
        if (pc.iceConnectionState === 'connected' || pc.iceConnectionState === 'completed') {
          console.log("‚úì Peer connection established!");
        }
      };
      
      pc.onconnectionstatechange = () => {
        console.log("üì° Connection state:", pc.connectionState);
        if (pc.connectionState === 'connected') {
          statusDiv.textContent = 'Status: Call connected!';
        }
      };
      
      pc.onicegatheringstatechange = () => {
        console.log("üßä ICE gathering state:", pc.iceGatheringState);
      };
    }

    // Get user media
    async function getUserMedia() {
      try {
        statusDiv.textContent = 'Status: Requesting camera access...';
        localStream = await navigator.mediaDevices.getUserMedia({ 
          video: true, 
          audio: true 
        });
        
        console.log("‚úì Got local media stream");
        const localVideo = document.getElementById('local');
        localVideo.srcObject = localStream;
        
        // Add tracks to peer connection
        localStream.getTracks().forEach(track => {
          console.log("Adding track to peer connection:", track.kind, track.id);
          pc.addTrack(track, localStream);
        });
        console.log("Total tracks added:", localStream.getTracks().length);
        
        statusDiv.textContent = 'Status: Waiting for calls...';
        
        // If there's already a pending offer, enable the accept button
        if (pendingOffer) {
          acceptBtn.disabled = false;
        }
      } catch (error) {
        console.error("‚úó Error getting user media:", error);
        statusDiv.textContent = 'Status: Camera access denied';
        alert("Error accessing camera/microphone: " + error.message);
      }
    }

    // Accept a call
    async function acceptCall() {
      if (!pendingOffer) {
        alert("No incoming call to accept");
        return;
      }
      
      if (!localStream) {
        alert("Camera/microphone not ready yet. Please wait.");
        return;
      }
      
      if (!socket || socket.readyState !== WebSocket.OPEN) {
        alert("Not connected to server. Please wait for reconnection.");
        return;
      }
      
      try {
        acceptBtn.disabled = true;
        acceptBtn.textContent = 'Accepting...';
        statusDiv.textContent = 'Status: Accepting call...';
        tracksReceived = 0; // Reset for new call
        remoteStream = null;
        
        console.log("‚Üí Setting remote description from pending offer");
        await pc.setRemoteDescription(new RTCSessionDescription(pendingOffer));
        console.log("‚úì Remote description set from offer");
        
        console.log("‚Üí Adding stored ICE candidates");
        for (const candidate of pendingIceCandidates) {
          await pc.addIceCandidate(new RTCIceCandidate(candidate));
        }
        pendingIceCandidates = [];
        
        console.log("‚Üí Creating answer");
        const answer = await pc.createAnswer({
          offerToReceiveAudio: true,
          offerToReceiveVideo: true
        });
        await pc.setLocalDescription(answer);
        console.log("‚úì Local description (answer) set, sending answer");
        
        socket.send(JSON.stringify({
          type: "ANSWER",
          to: "phone",
          answer: answer
        }));
        
        pendingOffer = null;
        acceptBtn.textContent = 'Call Accepted ‚úì';
        statusDiv.textContent = 'Status: Call connected!';
        
        console.log("‚úì Call accepted successfully");
      } catch (error) {
        console.error("‚úó Error accepting call:", error);
        statusDiv.textContent = 'Status: Failed to accept call';
        acceptBtn.disabled = false;
        acceptBtn.textContent = 'Accept Call';
        alert("Error accepting call: " + error.message);
      }
    }

    // Initialize everything
    window.onload = () => {
      initPeerConnection();
      connectWebSocket();
      getUserMedia();
      
      // Add event listeners to remote video for debugging
      const remoteVideo = document.getElementById('remote');
      remoteVideo.addEventListener('loadedmetadata', () => {
        console.log('‚úì Remote video metadata loaded');
      });
      remoteVideo.addEventListener('loadeddata', () => {
        console.log('‚úì Remote video data loaded');
      });
      remoteVideo.addEventListener('playing', () => {
        console.log('‚úì Remote video is playing');
      });
    };
  </script>
</body>
</html>
